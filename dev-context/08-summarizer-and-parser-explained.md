# Summarizer and Parser: What They Do and Context Benefits

## Overview

The bot uses four different LLM roles:
1. **Default**: Main forecasting model (generates reasoning and predictions)
2. **Researcher**: Conducts research on questions
3. **Summarizer**: Summarizes research (currently **disabled**)
4. **Parser**: Extracts structured data from free-form text (currently **active**)

## Summarizer

### What It Does

The **Summarizer** is used to condense multiple research reports into a single, focused summary before forecasting.

**Current Status**: ⚠️ **DISABLED** (`use_research_summary_to_forecast=False` on line 732)

**When It Would Be Used:**
- If `use_research_summary_to_forecast=True`
- When `research_reports_per_question > 1` (multiple research reports generated)
- Before the forecasting phase begins

**Purpose:**
- Takes multiple research reports (e.g., 3 different research summaries)
- Condenses them into one coherent summary
- Provides a cleaner, more focused research context for the forecaster

**Example Workflow (if enabled):**
```
Research Report 1: "Recent news shows..."
Research Report 2: "Expert opinions indicate..."
Research Report 3: "Market data suggests..."

↓ Summarizer processes all three

Summarized Research: "Key findings: [synthesized summary of all three]"

↓ Used in forecast prompts
```

### Would Context Help the Summarizer?

**Yes, but limited benefit** ⚠️

**Potential Benefits:**
- ✅ Could guide what to emphasize in summaries (e.g., "Focus on quantitative data over opinions")
- ✅ Could specify summary length/style preferences
- ✅ Could prioritize certain types of information

**Limitations:**
- ⚠️ Currently disabled, so no immediate benefit
- ⚠️ Summarization is a relatively straightforward task
- ⚠️ The summarizer already receives the research reports as context

**Recommendation:**
- **Low priority** - Only add context if you enable summarization
- If you do enable it, add context like:
  ```
  - Prioritize quantitative data and expert assessments
  - Emphasize recent developments over historical context
  - Keep summaries concise but comprehensive
  ```

## Parser

### What It Does

The **Parser** extracts structured data from the free-form reasoning text generated by the default model.

**Current Status**: ✅ **ACTIVE** (used for all question types)

**How It Works:**

1. **Default model** generates reasoning text like:
   ```
   "Based on the research, I think there's a 65% chance this will happen.
   The key factors are X, Y, and Z. 
   Probability: 65%"
   ```

2. **Parser** extracts the structured data:
   - For binary: Extracts `0.65` (probability)
   - For numeric: Extracts percentiles `{10: 100, 20: 150, ...}`
   - For multiple choice: Extracts `{"Option A": 0.4, "Option B": 0.6}`

**Where It's Used:**
- **Binary questions** (line 264): Parses probability from reasoning
- **Multiple choice** (line 343): Parses option probabilities
- **Numeric questions** (line 444): Parses percentile values
- **Date questions** (line 539): Parses date percentiles

**What It Receives:**
- The reasoning text from the default model
- The target output type (BinaryPrediction, PredictedOptionList, etc.)
- Additional parsing instructions (units, option names, bounds, etc.)
- Question-specific context (question text, units, bounds)

**Example Parsing Instructions (for numeric questions):**
```
- The units for the forecast are: "B $"
- Make sure to give values in terms of the correct units
- If the answer gives numbers as $500,000,000 and units are "B $" 
  then parse as 0.5 (since $500,000,000 is $0.5 billion)
- Turn any values in scientific notation into regular numbers
```

### Would Context Help the Parser?

**Minimal benefit** ⚠️

**Why Context Has Limited Value:**

1. **Highly Technical Task**: Parsing is about extracting data, not interpretation
   - The parser needs to find numbers, dates, probabilities
   - It's more like a data extraction tool than a reasoning tool

2. **Already Receives Detailed Instructions**: 
   - Question-specific parsing instructions are already provided
   - Units, bounds, option names are all specified
   - The parser has all the context it needs

3. **Domain-Agnostic**: 
   - Parsing "65%" works the same whether it's about politics or technology
   - The extraction logic doesn't depend on domain knowledge

**Potential (Limited) Benefits:**

✅ **Could help with edge cases:**
- Domain-specific number formats
- Unusual date formats
- Special terminology that affects parsing

✅ **Could provide parsing preferences:**
- How to handle ambiguous cases
- Default behaviors when data is unclear

**Example Context (if you wanted to add it):**
```
- When parsing probabilities, interpret "likely" as 70-80%, "unlikely" as 20-30%
- For dates, prefer ISO format (YYYY-MM-DD)
- If units are ambiguous, check the question context
```

**Recommendation:**
- **Not recommended** - The parser already receives comprehensive instructions
- Parsing is a technical extraction task, not an interpretive one
- Adding context would likely have minimal impact
- Focus context on Researcher and Default models instead

## Comparison Table

| Role | Purpose | Context Benefit | Priority |
|------|---------|----------------|----------|
| **Researcher** | Find information | ✅ **High** - Guides what to search for | High |
| **Default** | Generate forecasts | ✅ **High** - Shapes reasoning and predictions | High |
| **Summarizer** | Condense research | ⚠️ **Low** - Currently disabled, limited benefit | Low |
| **Parser** | Extract structured data | ⚠️ **Minimal** - Technical task, already well-instructed | Very Low |

## Current Implementation

### Summarizer
- **Status**: Configured but not used (`use_research_summary_to_forecast=False`)
- **Location**: Defined in `llms` dict but not called
- **Would be called**: In parent `ForecastBot` class if summarization enabled

### Parser
- **Status**: Actively used for all question types
- **Location**: Called via `structure_output()` function
- **Frequency**: Once per forecast attempt (5 times per question by default)
- **Input**: Reasoning text + parsing instructions
- **Output**: Structured prediction objects

## Code Locations

### Parser Usage Examples:

**Binary Questions** (line 264):
```python
binary_prediction: BinaryPrediction = await structure_output(
    reasoning,  # Free-form text from default model
    BinaryPrediction,  # Target structure
    model=self.get_llm("parser", "llm"),  # Parser model
    num_validation_samples=self._structure_output_validation_samples,
)
```

**Numeric Questions** (line 444):
```python
percentile_list: list[Percentile] = await structure_output(
    reasoning,
    list[Percentile],
    model=self.get_llm("parser", "llm"),
    additional_instructions=parsing_instructions,  # Units, bounds, etc.
    num_validation_samples=self._structure_output_validation_samples,
)
```

## Recommendations

### For Summarizer Context:
1. **Don't add context yet** - It's disabled
2. **If you enable summarization**, then consider adding:
   - Summary length preferences
   - Information prioritization guidelines
   - Style preferences

### For Parser Context:
1. **Don't add context** - Not recommended
2. **Focus on improving parsing instructions** instead:
   - Make parsing instructions more specific
   - Add edge case handling in `parsing_instructions`
   - Improve the default model's output format (so parser has cleaner input)

### Better Use of Context:
- ✅ **Research Context**: High value - guides information gathering
- ✅ **Forecast Context**: High value - shapes predictions
- ❌ **Parser Context**: Low value - technical extraction task
- ⚠️ **Summarizer Context**: Low value - disabled and limited benefit

## Summary

**Summarizer:**
- Currently disabled
- Would summarize multiple research reports
- Context could help but limited benefit
- **Recommendation**: Skip unless you enable summarization

**Parser:**
- Actively used for all question types
- Extracts structured data from free-form text
- Already receives comprehensive instructions
- Context would have minimal benefit
- **Recommendation**: Don't add context; focus on improving parsing instructions instead

**Best Use of Context:**
Focus your context files on **Research Context** and **Forecast Context** - these have the highest impact on bot performance.
